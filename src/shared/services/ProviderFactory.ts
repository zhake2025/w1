/**
 * ä¾›åº”å•†å·¥å‚æ¨¡å— - å‚è€ƒæœ€ä½³å®ä¾‹æ¶æ„
 * è´Ÿè´£æ ¹æ®ä¾›åº”å•†ç±»å‹è¿”å›é€‚å½“çš„APIå¤„ç†æ¨¡å—
 */
import type { Model } from '../types';
import * as openaiApi from '../api/openai';
import * as anthropicApi from '../api/anthropic';
import * as geminiApi from '../api/gemini';
import { modelComboService } from './ModelComboService';
import { OpenAIAISDKProvider } from '../api/openai-aisdk';
import { OpenAIResponseProvider } from '../providers/OpenAIResponseProvider';


/**
 * è·å–å®é™…çš„æä¾›å•†ç±»å‹ - æ”¯æŒæ™ºèƒ½è·¯ç”±
 * @param model æ¨¡å‹é…ç½®
 * @returns æä¾›å•†ç±»å‹
 */
export function getActualProviderType(model: Model): string {
  // æ£€æŸ¥æ˜¯å¦ä¸ºæ¨¡å‹ç»„åˆ
  if (model.provider === 'model-combo' || (model as any).isCombo) {
    console.log(`[ProviderFactory] æ£€æµ‹åˆ°æ¨¡å‹ç»„åˆ: ${model.id}`);
    return 'model-combo';
  }

  // ä¼˜å…ˆä½¿ç”¨providerTypeå­—æ®µ(å¦‚æœå­˜åœ¨)ï¼Œå¦åˆ™å›é€€åˆ°providerå­—æ®µ
  let providerType = (model as any).providerType || model.provider;

  // æ™ºèƒ½è·¯ç”±ï¼šåªæœ‰åœ¨æ²¡æœ‰æ˜ç¡®æŒ‡å®šprovideræˆ–providerä¸º'auto'æ—¶æ‰è¿›è¡Œæ¨æ–­
  // å¦‚æœç”¨æˆ·æ˜ç¡®é€‰æ‹©äº†ä¾›åº”å•†ï¼Œå°±ä½¿ç”¨ç”¨æˆ·çš„é€‰æ‹©ï¼Œä¸è¿›è¡Œè‡ªåŠ¨æ¨æ–­
  if (!providerType || providerType === 'auto') {
    providerType = inferProviderFromModel(model);
  }

  console.log(`[ProviderFactory] è·å–æä¾›å•†ç±»å‹: ${providerType}, æ¨¡å‹ID: ${model.id}, åŸå§‹provider: ${model.provider}`);
  return providerType;
}

/**
 * æ™ºèƒ½æ¨æ–­Providerç±»å‹ - ç±»ä¼¼æœ€ä½³å®ä¾‹AiHubMixProviderçš„åŠŸèƒ½
 * @param model æ¨¡å‹é…ç½®
 * @returns æ¨æ–­çš„Providerç±»å‹
 */
function inferProviderFromModel(model: Model): string {
  // æ£€æŸ¥æ˜¯å¦ä¸ºAzure OpenAI
  if (isAzureOpenAI(model)) {
    return 'azure-openai';
  }

  // æ ¹æ®æ¨¡å‹IDæ¨æ–­providerç±»å‹
  const modelId = model.id.toLowerCase();

  if (modelId.includes('claude')) {
    return 'anthropic';
  }

  if (modelId.includes('gemini')) {
    return 'gemini';
  }

  if (modelId.includes('gpt') || modelId.includes('o1') || modelId.includes('davinci') || modelId.includes('curie') || modelId.includes('babbage') || modelId.includes('ada')) {
    return 'openai';
  }

  if (modelId.includes('deepseek')) {
    return 'deepseek';
  }

  if (modelId.includes('grok')) {
    return 'grok';
  }

  // é»˜è®¤ä½¿ç”¨openaiå…¼å®¹çš„API
  return 'openai';
}

/**
 * æ£€æŸ¥æ˜¯å¦ä¸ºAzure OpenAI
 * @param model æ¨¡å‹é…ç½®
 * @returns æ˜¯å¦ä¸ºAzure OpenAI
 */
function isAzureOpenAI(model: Model): boolean {
  return Boolean((model as any).providerType === 'azure-openai' ||
         model.provider === 'azure-openai' ||
         (model.baseUrl && model.baseUrl.includes('openai.azure.com')));
}

/**
 * è·å–ä¾›åº”å•†API - æ”¯æŒAzure OpenAIå’Œæ™ºèƒ½è·¯ç”±
 * @param model æ¨¡å‹é…ç½®
 * @returns ä¾›åº”å•†APIæ¨¡å—
 */
export function getProviderApi(model: Model): any {
  const providerType = getActualProviderType(model);

  // æ‰©å±•çš„Provideré€‰æ‹©é€»è¾‘ï¼Œæ”¯æŒAzure OpenAIå’Œæ¨¡å‹ç»„åˆ
  switch (providerType) {
    case 'model-combo':
      // è¿”å›æ¨¡å‹ç»„åˆAPI
      console.log(`[ProviderFactory] ä½¿ç”¨æ¨¡å‹ç»„åˆAPI`);
      return {
        sendChatRequest: async (messages: any[], model: Model, onUpdate?: (content: string) => void) => {
          return await handleModelComboRequest(messages, model, onUpdate);
        }
      };
    case 'anthropic':
      return anthropicApi;
    case 'gemini':
      return geminiApi;
    case 'azure-openai':
      // Azure OpenAIä½¿ç”¨OpenAIå…¼å®¹APIï¼Œä½†æœ‰ç‰¹æ®Šé…ç½®
      console.log(`[ProviderFactory] ä½¿ç”¨Azure OpenAI API`);
      return openaiApi;
    case 'openai-aisdk':
      // ä½¿ç”¨AI SDKç‰ˆæœ¬çš„OpenAI API
      console.log(`[ProviderFactory] ä½¿ç”¨AI SDK OpenAI API`);
      return {
        sendChatRequest: async (messages: any[], model: Model, onUpdate?: (content: string, reasoning?: string) => void) => {
          // ä½¿ç”¨å·²å¯¼å…¥çš„AI SDKæ¨¡å—
          const provider = new OpenAIAISDKProvider(model);
          return await provider.sendChatMessage(messages, { onUpdate });
        },
        testConnection: async (_model: Model) => {
          try {
            // ç®€å•çš„è¿æ¥æµ‹è¯•
            return true;
          } catch (error) {
            console.error('AI SDKè¿æ¥æµ‹è¯•å¤±è´¥:', error);
            return false;
          }
        }
      };
    case 'openai':
    case 'deepseek': // DeepSeekä½¿ç”¨OpenAIå…¼å®¹API
    case 'google':   // Googleä½¿ç”¨OpenAIå…¼å®¹API
    case 'grok':     // Grokä½¿ç”¨OpenAIå…¼å®¹API
    case 'siliconflow': // ç¡…åŸºæµåŠ¨ä½¿ç”¨OpenAIå…¼å®¹API
    case 'volcengine':  // ç«å±±å¼•æ“ä½¿ç”¨OpenAIå…¼å®¹API
    default:
      // é»˜è®¤ä½¿ç”¨OpenAIå…¼å®¹APIï¼Œä¸æœ€ä½³å®ä¾‹ä¿æŒä¸€è‡´
      return openaiApi;
  }
}

/**
 * æµ‹è¯•APIè¿æ¥
 * @param model æ¨¡å‹é…ç½®
 * @returns è¿æ¥æ˜¯å¦æˆåŠŸ
 */
export async function testConnection(model: Model): Promise<boolean> {
  try {
    const api = getProviderApi(model);
    return await api.testConnection(model);
  } catch (error) {
    console.error('APIè¿æ¥æµ‹è¯•å¤±è´¥:', error);
    return false;
  }
}

/**
 * æ£€æŸ¥æ˜¯å¦ä¸ºè§†é¢‘ç”Ÿæˆæ¨¡å‹
 */
function isVideoGenerationModel(model: Model): boolean {
  // æ£€æŸ¥æ¨¡å‹ç±»å‹
  if (model.modelTypes && model.modelTypes.includes('video_gen' as any)) {
    return true;
  }

  // æ£€æŸ¥è§†é¢‘ç”Ÿæˆæ ‡å¿—
  if ((model as any).videoGeneration || (model.capabilities as any)?.videoGeneration) {
    return true;
  }

  // åŸºäºæ¨¡å‹IDæ£€æµ‹
  return model.id.includes('HunyuanVideo') ||
         model.id.includes('Wan-AI/Wan2.1-T2V') ||
         model.id.includes('Wan-AI/Wan2.1-I2V') ||
         model.id.toLowerCase().includes('video');
}

/**
 * å‘é€èŠå¤©è¯·æ±‚
 * @param messages æ¶ˆæ¯æ•°ç»„
 * @param model æ¨¡å‹é…ç½®
 * @param onUpdate æ›´æ–°å›è°ƒå‡½æ•°
 * @returns å“åº”å†…å®¹
 */
export async function sendChatRequest(
  messages: any[],
  model: Model,
  onUpdate?: (content: string, reasoning?: string) => void
): Promise<string | { content: string; reasoning?: string; reasoningTime?: number }> {
  try {
    console.log(`[ProviderFactory.sendChatRequest] å¼€å§‹å¤„ç†è¯·æ±‚ - æ¨¡å‹ID: ${model.id}, æä¾›å•†: ${model.provider}`);

    // ğŸ¬ æ£€æŸ¥æ˜¯å¦ä¸ºè§†é¢‘ç”Ÿæˆæ¨¡å‹
    if (isVideoGenerationModel(model)) {
      console.log(`[ProviderFactory.sendChatRequest] æ£€æµ‹åˆ°è§†é¢‘ç”Ÿæˆæ¨¡å‹: ${model.id}`);
      throw new Error(`æ¨¡å‹ ${model.name || model.id} æ˜¯è§†é¢‘ç”Ÿæˆæ¨¡å‹ï¼Œä¸æ”¯æŒèŠå¤©å¯¹è¯ã€‚è¯·ä½¿ç”¨ä¸“é—¨çš„è§†é¢‘ç”ŸæˆåŠŸèƒ½ã€‚`);
    }

    // æ£€æŸ¥æ¨¡å‹æ˜¯å¦æœ‰APIå¯†é’¥
    if (!model.apiKey && model.provider !== 'auto') {
      // åªåœ¨å¼€å‘ç¯å¢ƒæ˜¾ç¤ºAPIå¯†é’¥è­¦å‘Š
      if (process.env.NODE_ENV === 'development') {
        console.warn(`[ProviderFactory.sendChatRequest] è­¦å‘Š: æ¨¡å‹ ${model.id} æ²¡æœ‰APIå¯†é’¥`);
      }
    }

    // å¼ºåˆ¶æ£€æŸ¥ï¼šç¡®ä¿æ¶ˆæ¯æ•°ç»„ä¸ä¸ºç©º
    if (!messages || !Array.isArray(messages) || messages.length === 0) {
      console.error('[ProviderFactory.sendChatRequest] ä¸¥é‡é”™è¯¯: æ¶ˆæ¯æ•°ç»„ä¸ºç©ºæˆ–æ— æ•ˆï¼Œæ·»åŠ é»˜è®¤æ¶ˆæ¯');

      // æ·»åŠ ä¸€ä¸ªé»˜è®¤çš„ç”¨æˆ·æ¶ˆæ¯
      messages = [{
        id: 'default-' + Date.now(),
        role: 'user',
        content: 'æ‚¨å¥½ï¼Œè¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„ï¼Ÿ', // ä½¿ç”¨æ›´å‹å¥½çš„é»˜è®¤æ¶ˆæ¯
        createdAt: new Date().toISOString(),
        updatedAt: new Date().toISOString(),
        blocks: []
      }];

      console.log('[ProviderFactory.sendChatRequest] æ·»åŠ é»˜è®¤ç”¨æˆ·æ¶ˆæ¯: æ‚¨å¥½ï¼Œè¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„ï¼Ÿ');
    }

    // è®°å½•æ¶ˆæ¯æ•°ç»„
    console.log(`[ProviderFactory.sendChatRequest] æ¶ˆæ¯æ•°ç»„:`, JSON.stringify(messages.map(msg => ({
      id: msg.id,
      role: msg.role,
      content: typeof msg.content === 'string' ?
        (msg.content.length > 50 ? msg.content.substring(0, 50) + '...' : msg.content) :
        '[å¤æ‚å†…å®¹]'
    }))));

    // è·å–åˆé€‚çš„APIå®ç°
    const api = getProviderApi(model);
    console.log(`[ProviderFactory.sendChatRequest] è·å–APIå®ç° - æä¾›å•†: ${model.provider}`);

    // ç¡®ä¿APIæœ‰sendChatRequestæ–¹æ³•
    if (!api.sendChatRequest) {
      console.error(`[ProviderFactory.sendChatRequest] é”™è¯¯: APIæ²¡æœ‰sendChatRequestæ–¹æ³•`);
      throw new Error(`æä¾›å•† ${model.provider} çš„APIæ²¡æœ‰sendChatRequestæ–¹æ³•`);
    }

    console.log(`[ProviderFactory.sendChatRequest] è°ƒç”¨APIçš„sendChatRequestæ–¹æ³•`);
    return await api.sendChatRequest(messages, model, onUpdate);
  } catch (error) {
    console.error('[ProviderFactory.sendChatRequest] å‘é€èŠå¤©è¯·æ±‚å¤±è´¥:', error);
    throw error;
  }
}

// è·å–é»˜è®¤åˆ†ç»„åç§° - ä»APIServiceç§»è¿‡æ¥ï¼Œç»Ÿä¸€ç®¡ç†
function getDefaultGroupName(modelId: string): string {
  const modelIdLower = modelId.toLowerCase();

  // GPT ç³»åˆ—
  if (modelIdLower.includes('gpt-4')) return 'GPT-4';
  if (modelIdLower.includes('gpt-3.5')) return 'GPT-3.5';

  // Claude ç³»åˆ—
  if (modelIdLower.includes('claude-3')) return 'Claude 3';
  if (modelIdLower.includes('claude-2')) return 'Claude 2';
  if (modelIdLower.includes('claude')) return 'Claude';

  // Gemini ç³»åˆ—
  if (modelIdLower.includes('gemini-1.5')) return 'Gemini 1.5';
  if (modelIdLower.includes('gemini-2')) return 'Gemini 2.0';
  if (modelIdLower.includes('gemini')) return 'Gemini';

  // Grok ç³»åˆ—
  if (modelIdLower.includes('grok-3')) return 'Grok 3';
  if (modelIdLower.includes('grok')) return 'Grok';

  // DeepSeek ç³»åˆ—
  if (modelIdLower.includes('deepseek')) return 'DeepSeek';

  // Qwen ç³»åˆ—
  if (modelIdLower.includes('qwen') || modelIdLower.includes('qvq') || modelIdLower.includes('qwq')) return 'Qwen';

  // THUDM/GLM ç³»åˆ—
  if (modelIdLower.includes('thudm') || modelIdLower.includes('glm')) return 'GLM';

  // BAAI ç³»åˆ—
  if (modelIdLower.includes('baai') || modelIdLower.includes('bge')) return 'BAAI';

  // Stability AI ç³»åˆ—
  if (modelIdLower.includes('stabilityai') || modelIdLower.includes('stable-diffusion')) return 'Stability AI';

  // Black Forest Labs ç³»åˆ—
  if (modelIdLower.includes('black-forest-labs') || modelIdLower.includes('flux')) return 'FLUX';

  // éŸ³é¢‘æ¨¡å‹
  if (modelIdLower.includes('funaudiollm') || modelIdLower.includes('sensevoice') || modelIdLower.includes('cosyvoice') ||
      modelIdLower.includes('fishaudio') || modelIdLower.includes('fish-speech') || modelIdLower.includes('rvc-boss') ||
      modelIdLower.includes('gpt-sovits')) return 'éŸ³é¢‘æ¨¡å‹';

  // åµŒå…¥æ¨¡å‹
  if (modelIdLower.includes('embedding') || modelIdLower.includes('bce-embedding') || modelIdLower.includes('reranker')) return 'åµŒå…¥æ¨¡å‹';

  // InternLM ç³»åˆ—
  if (modelIdLower.includes('internlm')) return 'InternLM';

  // ç½‘æ˜“æœ‰é“
  if (modelIdLower.includes('netease-youdao')) return 'ç½‘æ˜“æœ‰é“';

  // Kolors ç³»åˆ—
  if (modelIdLower.includes('kwai-kolors') || modelIdLower.includes('kolors')) return 'Kolors';

  // Wan AI ç³»åˆ—
  if (modelIdLower.includes('wan-ai')) return 'Wan AI';

  // MiniMax ç³»åˆ—
  if (modelIdLower.includes('minimax')) return 'MiniMax';

  // Pro ç‰ˆæœ¬æ¨¡å‹
  if (modelIdLower.startsWith('pro/')) return 'Pro æ¨¡å‹';

  // LoRA ç‰ˆæœ¬æ¨¡å‹
  if (modelIdLower.startsWith('lora/')) return 'LoRA æ¨¡å‹';

  return 'å…¶ä»–æ¨¡å‹';
}

/**
 * ä»é»˜è®¤ç«¯ç‚¹è·å–æ¨¡å‹åˆ—è¡¨
 * @param provider æä¾›å•†é…ç½®
 * @param providerType æä¾›å•†ç±»å‹
 * @returns åŸå§‹æ¨¡å‹åˆ—è¡¨
 */
async function fetchModelsFromEndpoint(provider: any, providerType: string): Promise<any[]> {
  let rawModels: any[] = [];

  // ç®€åŒ–çš„Provideré€‰æ‹©é€»è¾‘ï¼Œä¸æœ€ä½³å®ä¾‹ä¿æŒä¸€è‡´
  switch (providerType.toLowerCase()) {
    case 'anthropic':
      rawModels = await anthropicApi.fetchModels(provider);
      break;
    case 'gemini':
      rawModels = await geminiApi.fetchModels(provider);
      break;
    case 'deepseek':
      // DeepSeekä½¿ç”¨OpenAIå…¼å®¹APIï¼Œå¤±è´¥æ—¶è¿”å›é¢„è®¾åˆ—è¡¨
      try {
        rawModels = await openaiApi.fetchModels(provider);
      } catch (error) {
        console.warn(`[fetchModelsFromEndpoint] DeepSeekæ¨¡å‹è·å–å¤±è´¥ï¼Œè¿”å›é¢„è®¾åˆ—è¡¨:`, error);
        rawModels = [
          { id: 'deepseek-chat', name: 'DeepSeek-V3', description: 'DeepSeekæœ€æ–°çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå…·æœ‰ä¼˜ç§€çš„ä¸­æ–‡å’Œä»£ç èƒ½åŠ›ã€‚', owned_by: 'deepseek' },
          { id: 'deepseek-reasoner', name: 'DeepSeek-R1', description: 'DeepSeekçš„æ¨ç†æ¨¡å‹ï¼Œæ“…é•¿è§£å†³å¤æ‚æ¨ç†é—®é¢˜ã€‚', owned_by: 'deepseek' }
        ];
      }
      break;
    case 'zhipu':
      // æ™ºè°±AIä¸æ”¯æŒæ ‡å‡†çš„ /v1/models æ¥å£ï¼Œè¿”å›é¢„è®¾åˆ—è¡¨
      console.log(`[fetchModelsFromEndpoint] æ™ºè°±AIä½¿ç”¨é¢„è®¾æ¨¡å‹åˆ—è¡¨`);
      rawModels = [
        { id: 'glm-5-plus', name: 'GLM-5-Plus', description: 'GLM-5å¢å¼ºç‰ˆï¼Œæœ€æ–°ä¸€ä»£å¤§æ¨¡å‹', owned_by: 'zhipu' },
        { id: 'glm-5-air', name: 'GLM-5-Air', description: 'GLM-5è½»é‡ç‰ˆï¼Œå¹³è¡¡æ€§èƒ½ä¸é€Ÿåº¦', owned_by: 'zhipu' },
        { id: 'glm-4-0520', name: 'GLM-4-0520', description: 'GLM-4æœ€æ–°ç‰ˆæœ¬ï¼Œæ€§èƒ½ä¼˜åŒ–', owned_by: 'zhipu' },
        { id: 'glm-4-plus', name: 'GLM-4-Plus', description: 'GLM-4å¢å¼ºç‰ˆï¼Œæ›´å¼ºæ¨ç†èƒ½åŠ›', owned_by: 'zhipu' },
        { id: 'glm-4-long', name: 'GLM-4-Long', description: 'GLM-4é•¿æ–‡æœ¬ç‰ˆï¼Œæ”¯æŒè¶…é•¿ä¸Šä¸‹æ–‡', owned_by: 'zhipu' },
        { id: 'glm-4-air', name: 'GLM-4-Air', description: 'GLM-4è½»é‡ç‰ˆï¼Œå¿«é€Ÿå“åº”', owned_by: 'zhipu' },
        { id: 'glm-4-airx', name: 'GLM-4-AirX', description: 'GLM-4è½»é‡å¢å¼ºç‰ˆ', owned_by: 'zhipu' },
        { id: 'glm-4-flash', name: 'GLM-4-Flash', description: 'GLM-4æé€Ÿç‰ˆï¼Œè¶…å¿«å“åº”', owned_by: 'zhipu' },
        { id: 'glm-4-flashx', name: 'GLM-4-FlashX', description: 'GLM-4æé€Ÿå¢å¼ºç‰ˆ', owned_by: 'zhipu' },
        { id: 'glm-4v', name: 'GLM-4V', description: 'GLM-4è§†è§‰ç‰ˆï¼Œæ”¯æŒå›¾åƒç†è§£', owned_by: 'zhipu' },
        { id: 'glm-4v-flash', name: 'GLM-4V-Flash', description: 'GLM-4Væé€Ÿç‰ˆ', owned_by: 'zhipu' },
        { id: 'glm-4v-plus', name: 'GLM-4V-Plus', description: 'GLM-4Vå¢å¼ºç‰ˆ', owned_by: 'zhipu' },
        { id: 'glm-4-alltools', name: 'GLM-4-AllTools', description: 'GLM-4å…¨å·¥å…·ç‰ˆï¼Œæ”¯æŒç½‘ç»œæœç´¢ç­‰å·¥å…·', owned_by: 'zhipu' }
      ];
      break;
    case 'openai-aisdk':
      // AI SDKç‰ˆæœ¬ä½¿ç”¨ç›¸åŒçš„æ¨¡å‹è·å–é€»è¾‘
      console.log(`[fetchModelsFromEndpoint] AI SDK OpenAIä½¿ç”¨æ ‡å‡†æ¨¡å‹è·å–`);
      rawModels = await openaiApi.fetchModels(provider);
      break;
    case 'openai-response':
      // OpenAI Responses API ä½¿ç”¨ä¸“é—¨çš„æ¨¡å‹è·å–é€»è¾‘
      console.log(`[fetchModelsFromEndpoint] OpenAI Responses APIä½¿ç”¨ä¸“é—¨çš„æ¨¡å‹è·å–`);
      try {
        // åˆ›å»º OpenAIResponseProvider å®ä¾‹æ¥è·å–æ¨¡å‹
        // ä½¿ç”¨é™æ€å¯¼å…¥çš„ OpenAIResponseProvider
        const responseProvider = new OpenAIResponseProvider({
          id: provider.id,
          name: provider.name || 'OpenAI Responses',
          apiKey: provider.apiKey,
          baseUrl: provider.baseUrl || 'https://api.openai.com/v1',
          provider: 'openai',
          providerType: 'openai-response'
        });
        rawModels = await responseProvider.getModels();
      } catch (error) {
        console.warn(`[fetchModelsFromEndpoint] OpenAI Responses APIæ¨¡å‹è·å–å¤±è´¥ï¼Œä½¿ç”¨æ ‡å‡†API:`, error);
        rawModels = await openaiApi.fetchModels(provider);
      }
      break;
    case 'openai':
    case 'google':
    default:
      // é»˜è®¤ä½¿ç”¨OpenAIå…¼å®¹API
      rawModels = await openaiApi.fetchModels(provider);
      break;
  }

  return rawModels;
}

/**
 * ä»è‡ªå®šä¹‰ç«¯ç‚¹è·å–æ¨¡å‹åˆ—è¡¨
 * @param customEndpoint è‡ªå®šä¹‰ç«¯ç‚¹å®Œæ•´URL
 * @param provider åŸå§‹æä¾›å•†é…ç½®ï¼ˆç”¨äºAPIå¯†é’¥ç­‰ï¼‰
 * @returns åŸå§‹æ¨¡å‹åˆ—è¡¨
 */
async function fetchModelsFromCustomEndpoint(customEndpoint: string, provider: any): Promise<any[]> {
  try {
    // ç›´æ¥ä½¿ç”¨è‡ªå®šä¹‰ç«¯ç‚¹ï¼Œä¸è¿›è¡Œä»»ä½•URLå¤„ç†
    console.log(`[fetchModelsFromCustomEndpoint] ç›´æ¥è¯·æ±‚è‡ªå®šä¹‰ç«¯ç‚¹: ${customEndpoint}`);

    // æ„å»ºè¯·æ±‚å¤´
    const headers: Record<string, string> = {
      'Content-Type': 'application/json'
    };

    // æ·»åŠ APIå¯†é’¥ï¼ˆå¦‚æœæœ‰ï¼‰
    if (provider.apiKey) {
      headers['Authorization'] = `Bearer ${provider.apiKey}`;
    }

    // æ·»åŠ è‡ªå®šä¹‰è¯·æ±‚å¤´ï¼ˆå¦‚æœæœ‰ï¼‰
    if (provider.extraHeaders) {
      Object.assign(headers, provider.extraHeaders);
    }

    // ç›´æ¥è¯·æ±‚è‡ªå®šä¹‰ç«¯ç‚¹ï¼Œä¸é€šè¿‡OpenAIçš„fetchModelså‡½æ•°
    const response = await fetch(customEndpoint, {
      method: 'GET',
      headers: headers
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.warn(`[fetchModelsFromCustomEndpoint] è‡ªå®šä¹‰ç«¯ç‚¹è¯·æ±‚å¤±è´¥: ${response.status}, ${errorText}`);
      throw new Error(`è‡ªå®šä¹‰ç«¯ç‚¹è¯·æ±‚å¤±è´¥: ${response.status}`);
    }

    const data = await response.json();
    console.log(`[fetchModelsFromCustomEndpoint] æˆåŠŸè·å–æ¨¡å‹åˆ—è¡¨, æ‰¾åˆ° ${(data.data || data || []).length} ä¸ªæ¨¡å‹`);

    // å¤„ç†ä¸åŒçš„å“åº”æ ¼å¼
    if (data.data && Array.isArray(data.data)) {
      // æ ‡å‡†OpenAIæ ¼å¼: {data: [...]}
      return data.data;
    } else if (Array.isArray(data)) {
      // ç›´æ¥è¿”å›æ•°ç»„æ ¼å¼
      return data;
    } else {
      console.warn(`[fetchModelsFromCustomEndpoint] æœªçŸ¥çš„å“åº”æ ¼å¼:`, data);
      return [];
    }
  } catch (error) {
    console.error(`[fetchModelsFromCustomEndpoint] è‡ªå®šä¹‰ç«¯ç‚¹è¯·æ±‚å¤±è´¥:`, error);
    throw error;
  }
}

/**
 * è·å–æ¨¡å‹åˆ—è¡¨ - ç®€åŒ–ç‰ˆæœ¬ï¼Œå‚è€ƒæœ€ä½³å®ä¾‹æ¶æ„
 * @param provider æä¾›å•†é…ç½®
 * @returns æ ¼å¼åŒ–çš„æ¨¡å‹åˆ—è¡¨
 */
export async function fetchModels(provider: any): Promise<any[]> {
  try {
    // ç¡®å®šæä¾›å•†ç±»å‹
    let providerType = provider.providerType || provider.id;

    // å¯¹äºè‡ªå®šä¹‰ä¸­è½¬ç«™ï¼Œé»˜è®¤ä½¿ç”¨OpenAIå…¼å®¹API
    if (provider.baseUrl && !provider.providerType && provider.id !== 'openai') {
      providerType = 'openai';
    }

    let allModels: any[] = [];

    // 1. ä»é»˜è®¤ç«¯ç‚¹è·å–æ¨¡å‹
    console.log(`[fetchModels] ä»é»˜è®¤ç«¯ç‚¹è·å–æ¨¡å‹: ${provider.id}`);
    try {
      const defaultModels = await fetchModelsFromEndpoint(provider, providerType);
      allModels.push(...defaultModels);
      console.log(`[fetchModels] é»˜è®¤ç«¯ç‚¹è·å–åˆ° ${defaultModels.length} ä¸ªæ¨¡å‹`);
    } catch (error) {
      console.warn(`[fetchModels] é»˜è®¤ç«¯ç‚¹è·å–å¤±è´¥:`, error);
    }

    // 2. å¦‚æœæœ‰è‡ªå®šä¹‰ç«¯ç‚¹ï¼Œä¹Ÿä»è‡ªå®šä¹‰ç«¯ç‚¹è·å–æ¨¡å‹
    if (provider.customModelEndpoint) {
      console.log(`[fetchModels] ä»è‡ªå®šä¹‰ç«¯ç‚¹è·å–æ¨¡å‹: ${provider.customModelEndpoint}`);
      try {
        const customModels = await fetchModelsFromCustomEndpoint(provider.customModelEndpoint, provider);
        allModels.push(...customModels);
        console.log(`[fetchModels] è‡ªå®šä¹‰ç«¯ç‚¹è·å–åˆ° ${customModels.length} ä¸ªæ¨¡å‹`);
      } catch (error) {
        console.warn(`[fetchModels] è‡ªå®šä¹‰ç«¯ç‚¹è·å–å¤±è´¥:`, error);
      }
    }

    // 3. å»é‡å¤„ç† - æ ¹æ®æ¨¡å‹IDå»é‡ï¼Œä¿ç•™ç¬¬ä¸€ä¸ª
    const uniqueModels = new Map();
    allModels.forEach(model => {
      if (!uniqueModels.has(model.id)) {
        uniqueModels.set(model.id, model);
      }
    });

    const deduplicatedModels = Array.from(uniqueModels.values());
    console.log(`[fetchModels] å»é‡åå…± ${deduplicatedModels.length} ä¸ªæ¨¡å‹`);

    // 4. ç»Ÿä¸€æ ¼å¼åŒ–æ¨¡å‹æ•°æ®
    const formattedModels = deduplicatedModels.map(model => ({
      id: model.id,
      name: model.name || model.id,
      provider: provider.id,
      providerType: provider.providerType || provider.id,
      description: model.description,
      group: getDefaultGroupName(model.id),
      enabled: true,
      // ä¿ç•™åŸå§‹æ•°æ®
      ...model
    }));

    return formattedModels;
  } catch (error) {
    console.error('è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥:', error);
    throw error;
  }
}

/**
 * å¤„ç†æ¨¡å‹ç»„åˆè¯·æ±‚
 * @param messages æ¶ˆæ¯æ•°ç»„
 * @param model æ¨¡å‹é…ç½®ï¼ˆåŒ…å«ç»„åˆä¿¡æ¯ï¼‰
 * @param onUpdate æ›´æ–°å›è°ƒå‡½æ•°
 * @returns å“åº”å†…å®¹
 */
async function handleModelComboRequest(
  messages: any[],
  model: Model,
  onUpdate?: (content: string) => void
): Promise<string | { content: string; reasoning?: string; reasoningTime?: number }> {
  try {
    console.log(`[handleModelComboRequest] å¼€å§‹å¤„ç†æ¨¡å‹ç»„åˆè¯·æ±‚: ${model.id}`);

    // ä»æ¨¡å‹é…ç½®ä¸­è·å–ç»„åˆé…ç½®
    const comboConfig = (model as any).comboConfig;
    if (!comboConfig) {
      throw new Error(`æ¨¡å‹ç»„åˆ ${model.id} çš„é…ç½®ä¿¡æ¯ä¸å­˜åœ¨`);
    }

    // å°†æ¶ˆæ¯è½¬æ¢ä¸ºç®€å•çš„æç¤ºè¯æ ¼å¼
    const prompt = messages
      .filter(msg => msg.role === 'user')
      .map(msg => msg.content)
      .join('\n');

    console.log(`[handleModelComboRequest] æå–çš„æç¤ºè¯: ${prompt.substring(0, 100)}...`);

    // è°ƒç”¨æ¨¡å‹ç»„åˆæœåŠ¡æ‰§è¡Œ
    const result = await modelComboService.executeCombo(comboConfig.id, prompt);

    console.log(`[handleModelComboRequest] æ¨¡å‹ç»„åˆæ‰§è¡Œå®Œæˆ:`, result);

    // å¦‚æœæœ‰æ›´æ–°å›è°ƒï¼Œå‘é€æœ€ç»ˆç»“æœ
    if (onUpdate && result.finalResult?.content) {
      onUpdate(result.finalResult.content);
    }

    // è¿”å›æœ€ç»ˆç»“æœ
    return {
      content: result.finalResult?.content || 'æ¨¡å‹ç»„åˆæ‰§è¡Œå®Œæˆï¼Œä½†æ²¡æœ‰è¿”å›å†…å®¹',
      reasoning: result.finalResult?.reasoning,
      reasoningTime: result.stats?.totalLatency
    };
  } catch (error) {
    console.error('[handleModelComboRequest] æ¨¡å‹ç»„åˆè¯·æ±‚å¤±è´¥:', error);
    throw new Error(`æ¨¡å‹ç»„åˆæ‰§è¡Œå¤±è´¥: ${error instanceof Error ? error.message : String(error)}`);
  }
}
